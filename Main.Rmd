---
title: "Proyecto Final - Efecto del Clima y Factores Ambientales en la Productividad
  Agrícola"
author: "Est. Apl. 2"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción al Problema

La agricultura desempeña un papel esencial en la seguridad alimentaria y el desarrollo económico global. Sin embargo, la creciente presión de factores como el cambio climático, el agotamiento de recursos naturales y la degradación del suelo ha planteado desafíos sin precedentes para mantener niveles sostenibles de productividad agrícola. En este contexto, comprender la relación entre los factores climáticos y la productividad agrícola se convierte en una prioridad para investigadores, responsables de políticas y agricultores.

Este proyecto tiene como objetivo identificar y cuantificar el efecto de factores como la temperatura promedio, la precipitación total, las emisiones de CO2 y los eventos climáticos extremos en la productividad agrícola. Utilizando herramientas estadísticas avanzadas y datos globales, buscamos responder preguntas estas críticas:

- ¿Qué factores ambientales tienen un efecto significativo en los cultivos? 
- ¿Qué modelo predictivo permite estimar con mayor precisión la productividad agrícola bajo diferentes escenarios climáticos?

La relevancia de este análisis radica en su potencial para guiar decisiones informadas. Con la implementación de modelos estadísticos robustos, es posible no solo identificar las variables más influyentes, sino también evaluar cómo estas interacciones pueden informar estrategias de adaptación, como el manejo eficiente del agua, la selección de cultivos más resistentes y el diseño de políticas agrícolas sostenibles. Este estudio pretende contribuir a la construcción de sistemas agrícolas más resilientes, capaces de enfrentar los desafíos del siglo XXI.



# Resumen del Análisis Estadístico

El presente proyecto analiza la influencia de factores climáticos y ambientales en la productividad agrícola global, utilizando un modelo estadístico basado en datos provenientes de distintas regiones del mundo. Se trabajó con un conjunto de datos de Kaggle compuesto por más de 10,000 observaciones y variables clave como temperatura promedio, precipitación total, tipo de cultivo y eventos climáticos extremos. La variable objetivo, productividad agrícola medida en toneladas métricas por hectárea, presentó una distribución asimétrica positiva, lo que motivó el uso de modelos lineales generalizados (GLM) con distribución Gamma y enlaces logarítmico e inverso.

A través de comparaciones basadas en AIC, BIC y pseudo $R^2$, el modelo reducido con enlace logarítmico emergió como el más eficiente, con un AIC de 26824.27 y un pseudo $R^2$ de 0.0788. Este modelo identificó la temperatura promedio, la precipitación y el tipo de cultivo como los predictores más relevantes. Los gráficos de residuos confirmaron la validez del modelo, aunque algunos patrones residuales sugieren la necesidad de estudios más profundos.

En el análisis de correlaciones, se destacó que la relación entre la temperatura promedio y la productividad agrícola no es lineal; se observa un incremento en la productividad a medida que las temperaturas aumentan hasta un rango óptimo ($\sim 25^\circ C$), pero más allá de este umbral, los rendimientos disminuyen drásticamente. Esta relación concuerda con estudios previos que indican que temperaturas extremadamente altas generan estrés térmico en los cultivos. Adicionalmente, aunque las precipitaciones mostraron una correlación más débil, se identificó que tanto los déficits como los excesos de lluvia afectan negativamente el rendimiento, confirmando la necesidad de un equilibrio hídrico para maximizar la productividad agrícola.

Otro aspecto estadístico relevante fue la evaluación de interacciones entre variables categóricas y numéricas utilizando el coeficiente Eta Squared, que mostró que las regiones explican una mayor proporción de la variabilidad en la productividad agrícola en comparación con factores como el tipo de cultivo o las estrategias de adaptación. Este hallazgo refuerza la importancia del contexto geográfico en la productividad agrícola. Por su parte, los resultados del cálculo de Cramér’s V entre variables categóricas revelaron una fuerte asociación entre las regiones y los tipos de cultivos, lo que sugiere que ciertas áreas están especializadas en cultivos específicos debido a su clima y características edafológicas. Estas interacciones fueron fundamentales para ajustar los modelos predictivos de manera más precisa.

En conclusión, el análisis revela que los efectos del clima, en particular temperaturas extremas y precipitaciones fuera de rango, son factores críticos que influyen en la productividad agrícola. Este proyecto ofrece herramientas para guiar políticas agrícolas y estrategias adaptativas, como el manejo eficiente de recursos hídricos y la selección de cultivos más resilientes, en un contexto de cambio climático.



# Marco Teórico

## Variabilidad climática y producción agrícola

Las relaciones no lineales entre la temperatura, la precipitación y la productividad agrícola son fundamentales para identificar umbrales críticos y desarrollar estrategias adaptativas frente a los efectos del cambio climático. La variabilidad climática, que incluye cambios en la temperatura y patrones de precipitación, afecta de manera compleja la productividad agrícola. Estudios han demostrado que el aumento de la temperatura puede tener efectos adversos en el rendimiento de cultivos como el arroz, donde se ha observado que los umbrales críticos de temperatura pueden determinar la viabilidad de la producción (Atedhor, 2019; Ojo \& Baiyegunhi, 2020). Además, la interacción entre la temperatura y la precipitación puede crear condiciones que exacerban la sequía o el exceso de humedad, afectando negativamente el crecimiento de los cultivos (Panda et al., 2019; Huang et al., 2020).

La identificación de estos umbrales críticos es esencial para la planificación agrícola y la implementación de estrategias adaptativas. En regiones donde la temperatura excede ciertos niveles, los cultivos pueden experimentar una disminución en la calidad y cantidad de producción, lo que resalta la necesidad de ajustar las prácticas agrícolas, como el cambio en los tiempos de siembra o la selección de variedades de cultivos más resistentes (Singh et al., 2022; Siddiqui et al., 2022). La investigación también sugiere que la adopción de estrategias de adaptación, como el uso de tecnologías de riego y la implementación de prácticas de agricultura inteligente frente al clima, puede mitigar los efectos negativos del cambio climático y mejorar la resiliencia de los sistemas agrícolas (Ahmed et al., 2019; Sadiku et al., 2017).

Además, la comprensión de las relaciones no lineales entre estos factores climáticos permite a los agricultores y a los responsables de políticas anticipar y responder a los cambios en la productividad agrícola. Se ha encontrado que la productividad de cultivos como la caña de azúcar presenta relaciones no lineales con las temperaturas, lo que implica que pequeñas variaciones en las condiciones climáticas pueden tener efectos desproporcionados en el rendimiento (Kumar, 2014). Esto subraya la importancia de monitorear y modelar estas relaciones para desarrollar políticas agrícolas efectivas que se adapten a las condiciones climáticas cambiantes.

## Modelos lineales generalizados

Los Modelos Lineales Generalizados (GLM) presentan ventajas significativas sobre los modelos lineales clásicos, especialmente en contextos donde los datos no siguen una distribución normal. Una de las principales ventajas de los GLM es su capacidad para manejar diferentes tipos de distribuciones de respuesta, lo que permite modelar datos que son binarios, de conteo o que presentan heterocedasticidad, entre otros (Vélez \& Correa, 2013; Canales \& Arana, 2012). Esto es crucial en muchas aplicaciones prácticas, como en epidemiología, donde se ha observado que los GLM pueden ajustarse mejor a los datos de mortalidad y otros fenómenos que no se distribuyen normalmente (Bonilla-Carrión et al., 2023).

Los modelos estadísticos, como los GLM utilizados en este proyecto, son herramientas clave para analizar datos con distribuciones no normales. En este caso, la distribución Gamma es ideal para modelar variables con asimetría positiva, como la productividad agrícola. La selección de funciones de enlace logarítmico e inverso permite explorar diferentes relaciones entre predictores y la variable objetivo. Métricas como el AIC (Criterio de Información de Akaike) y el BIC (Criterio de Información Bayesiano) son fundamentales para evaluar la eficiencia de los modelos, penalizando aquellos con mayor complejidad.

## Análisis de residuos y validación de ajuste

Los residuos, y en particular el residuo de Pearson, son herramientas cruciales para evaluar la validez de los supuestos estadísticos y la calidad del ajuste en los Modelos Lineales Generalizados (GLM). Los residuos de Pearson se calculan como la diferencia entre los valores observados y los valores predichos, normalizados por la desviación estándar de los valores predichos. Este enfoque permite identificar patrones en los residuos que pueden indicar problemas en el modelo, como la falta de ajuste, la heterocedasticidad o la especificación incorrecta de la distribución de la variable dependiente (Botero \& Barajas, 2017).

Un análisis de los residuos de Pearson puede revelar si los supuestos de independencia, homocedasticidad y normalidad de los errores se cumplen. Por ejemplo, si los residuos muestran una tendencia sistemática o patrones no aleatorios, esto sugiere que el modelo no está capturando adecuadamente la relación entre las variables, lo que podría llevar a inferencias erróneas (Botero \& Barajas, 2017). La identificación de tales patrones permite a los investigadores ajustar el modelo, ya sea mediante la inclusión de términos adicionales, la transformación de variables o el uso de un modelo diferente que se ajuste mejor a la naturaleza de los datos (Corrales, 2020; Díaz-Quijano, 2016).

La mejora en la calidad del ajuste a través del análisis de residuos también tiene un impacto directo en el desempeño predictivo del modelo. Un modelo que se ajusta bien a los datos históricos es más probable que realice predicciones precisas en nuevos datos. Por ejemplo, en estudios de modelación predictiva, se ha demostrado que los modelos que consideran adecuadamente los residuos y ajustan sus especificaciones en consecuencia pueden mejorar significativamente la precisión de las proyecciones (Corrales, 2020). Esto es especialmente relevante en contextos como la predicción de siniestros en seguros o la estimación de la productividad agrícola, donde la precisión de las predicciones puede tener implicaciones económicas significativas (Corrales, 2020).

Además, la eliminación de valores atípicos y el análisis de multicolinealidad son esenciales para garantizar la estabilidad y validez de los modelos. Herramientas como la correlación de Pearson, el coeficiente Eta Squared y Cramér’s V permiten identificar relaciones significativas entre variables numéricas y categóricas, proporcionando un marco robusto para interpretar la interacción entre el clima y la productividad agrícola. Este enfoque estadístico ayuda a traducir datos complejos en estrategias concretas para mitigar los impactos del cambio climático en la agricultura.



# Análisis de Datos

El conjunto de datos utilizado en este análisis proviene de Kaggle y está disponible en el siguiente enlace: [Global Agriculture Climate Impact Dataset](https://www.kaggle.com/datasets/talhachoudary/global-agriculture-climate-impact-dataset?resource=download). Este dataset ofrece información detallada sobre la interacción entre factores climáticos, ambientales y agrícolas, y su impacto en la productividad de los cultivos. A continuación, se describen las variables incluidas en el dataset:

- **`Crop_Yield_MT_per_HA`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Productividad agrícola medida en toneladas métricas por hectárea. Esta es la variable objetivo del análisis.  

- **`Year`**  
  - **Tipo**: Numérica entera  
  - **Descripción**: Año en que se registraron los datos.  

- **`Country`**  
  - **Tipo**: Categórica  
  - **Descripción**: País donde se recopiló la información.

- **`Region`**  
  - **Tipo**: Categórica  
  - **Descripción**: Región específica dentro del país, utilizada para un análisis más granular.  

- **`Crop_Type`**  
  - **Tipo**: Categórica  
  - **Descripción**: Tipo de cultivo analizado (e.g., trigo, maíz, arroz).

- **`Average_Temperature_C`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Temperatura promedio registrada durante la temporada de cultivo.

- **`Total_Precipitation_mm`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Precipitación total (en milímetros) durante la temporada de cultivo.

- **`CO2_Emissions_MT`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Emisiones de CO2 (en toneladas métricas) relacionadas con actividades agrícolas o de la región.  

- **`Extreme_Weather_Events`**  
  - **Tipo**: Numérica entera  
  - **Descripción**: Numero de eventos climáticos extremos (e.g., sequías, inundaciones) durante la temporada.  

- **`Irrigation_Access_%`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Porcentaje del área de cultivo que cuenta con acceso a sistemas de riego.

- **`Pesticide_Use_KG_per_HA`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Uso de pesticidas en kilogramos por hectárea.

- **`Fertilizer_Use_KG_per_HA`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Cantidad de fertilizantes utilizados por hectárea.

- **`Soil_Health_Index`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Índice que evalua la calidad y salud del suelo.

- **`Adaptation_Strategies`**  
  - **Tipo**: Categórica  
  - **Descripción**: Estrategias adoptadas para mitigar o adaptarse a los efectos del clima (e.g., rotación de cultivos, manejo de agua).  

- **`Economic_Impact_Million_USD`**  
  - **Tipo**: Numérica continua  
  - **Descripción**: Impacto económico de la venta de los cultivos (estimado en millones de dólares).

Este dataset proporciona una base rica para explorar las relaciones entre los factores ambientales y climáticos, y la productividad agrícola a nivel global.

Cargamos librerías
```{r, message=FALSE, warning=FALSE, results='hide'}
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("effectsize")) install.packages("effectsize") # Para calcular eta squared
if (!require("knitr")) install.packages("knitr")# Instalar y cargar paquetes necesarios
if (!require("vcd")) install.packages("vcd") # Para calcular Cramér's V
if (!require("countrycode")) install.packages("countrycode") # Para agrupar países en continentes
if (!require("naniar")) install.packages("naniar") # Para visualizar datos faltantes
if (!require("patchwork")) install.packages("patchwork")
if (!require("gridExtra")) install.packages("gridExtra")
if (!require("reshape2")) install.packages("reshape2")
if (!require("boot")) install.packages("boot")
library(boot)
library(reshape2)
library(gridExtra)
library(patchwork)
library(naniar)
library(countrycode)
library(vcd)
library(knitr)
library(tidyverse)
library(effectsize) 
```


Cargamos ahora los datos y pasamos **`Crop_Yield_MT_per_HA`** como la primer columna
```{r}
file_path <- "Data/climate_change_impact_on_agriculture_2024.csv"
# Data obtained from https://www.kaggle.com/datasets/talhachoudary/global-agriculture-climate-impact-dataset
climate_data <- read.csv(file_path)
climate_data <- climate_data[, c("Crop_Yield_MT_per_HA", setdiff(names(climate_data), "Crop_Yield_MT_per_HA"))]
```


## Datos faltantes
```{r}
# Resumen de datos faltantes por columna
missing_summary <- climate_data %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  mutate(Missing_Percentage = (Missing_Count / nrow(climate_data)) * 100)

# Mostrar resumen
missing_summary %>%
  arrange(desc(Missing_Percentage)) %>%
  knitr::kable(format = "markdown", caption = "Datos Faltantes por Variable")

```

Como no hay datos faltantes, continuamos.


## Variables Numéricas: Boxplots e histogramas
Los siguientes boxplots e histogramas muestran la distribución de las variables numéricas en el dataset.




Boxplot e histograma de `Crop_Yield_MT_per_HA`
```{r boxplot-crop-yield}
x <- climate_data$Crop_Yield_MT_per_HA

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot de Productividad Agrícola", 
     xlab = "Rendimiento de Cultivo (MT/HA)", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()
```

Boxplot e histograma de `Year`
```{r boxplot-year}
x <- climate_data$Year

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot del Año", 
     xlab = "Año", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()

```

Boxplot e histograma de `Average_Temperature_C`
```{r boxplot-temp}
x <- climate_data$Average_Temperature_C

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot de Temperatura Promedio", 
     xlab = "Temperatura Promedio (°C)", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()
```

Boxplot e historgama de `Total_Precipitation_mm`
```{r boxplot-precipitation}
x <- climate_data$Total_Precipitation_mm

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot de Precipitación Total", 
     xlab = "Precipitación Total (mm)", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()

```

Boxplot e histograma de `CO2_Emissions_MT`
```{r boxplot-co2}
x <- climate_data$CO2_Emissions_MT

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot de Emisiones de CO2", 
     xlab = "Emisiones de CO2 (MT)", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()

```

Boxplot e histograma de `Extreme_Weather_Events`
```{r boxplot-weather-events}
x <- climate_data$Extreme_Weather_Events

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot de Eventos Climáticos Extremos", 
     xlab = "Número de Eventos Climáticos Extremos", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()
```

Boxplot e histograma de `Irrigation_Access_%`
```{r boxplot-irrigation}
x <- climate_data$Irrigation_Access_.

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot de Acceso a Riego", 
     xlab = "Porcentaje de Acceso a Riego (%)", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()
```

Boxplot e histograma de `Pesticide_Use_KG_per_HA`
```{r boxplot-pesticide}
x <- climate_data$Pesticide_Use_KG_per_HA

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot de Uso de Pesticidas", 
     xlab = "Uso de Pesticidas (KG/HA)", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()

```

Boxplot e histograma de `Fertilizer_Use_KG_per_HA`
```{r boxplot-fertilizer}
x <- climate_data$Fertilizer_Use_KG_per_HA

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot de Uso de Fertilizantes", 
     xlab = "Uso de Fertilizantes (KG/HA)", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()

```

Boxplot e histograma de `Soil_Health_Index`
```{r boxplot-soil-health}
x <- climate_data$Soil_Health_Index

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot del Índice de Salud del Suelo", 
     xlab = "Índice de Salud del Suelo", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()

```

Boxplot e histograma de `Economic_Impact_Million_USD`
```{r boxplot-economic-impact}
x <- climate_data$Economic_Impact_Million_USD

hist(x, prob = TRUE, 
     col = "lightblue", 
     main = "Histograma y Boxplot del Impacto Económico", 
     xlab = "Impacto Económico (Millones de USD)", 
     ylab = "Densidad")

par(new = TRUE)

boxplot(x, horizontal = TRUE, axes = FALSE, 
        col = rgb(0, 1, 0, alpha = 0.5), 
        at = 0.25, 
        height = 0.005, 
        whisklty = 1, whisklwd = 2, staplewex = 0.5, staplelwd = 2)

box()

```



## Variables Categóricas: Frecuencias
A continuación, se presentan las frecuencias para las variables categóricas del dataset.

Frecuencia de Países **`Country`**
```{r}
# Crear la tabla de frecuencias y calcular el porcentaje
var_freq <- as.data.frame(table(climate_data$Country))
colnames(var_freq) <- c("Country", "Frequency")
var_freq <- var_freq %>%
  mutate(Percentage = (Frequency / sum(Frequency)) * 100)

# Crear la gráfica combinada de frecuencia y porcentaje
ggplot(var_freq, aes(x = reorder(Country, -Frequency), y = Frequency)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
            vjust = -0.5, size = 3.5, color = "black") +
  theme_minimal() +
  labs(
    title = "Frecuencia y Porcentaje de Países",
    x = "País",
    y = "Frecuencia"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Frecuencia de Regiones **`Region`**
```{r}
# Crear la tabla de frecuencias y calcular el porcentaje
var_freq <- as.data.frame(table(climate_data$Region))
colnames(var_freq) <- c("Region", "Frequency")
var_freq <- var_freq %>%
  mutate(Percentage = (Frequency / sum(Frequency)) * 100)

# Crear la gráfica combinada de frecuencia y porcentaje
ggplot(var_freq, aes(x = reorder(Region, -Frequency), y = Frequency)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
            vjust = -0.5, size = 3.5, color = "black") +
  theme_minimal() +
  labs(
    title = "Frecuencia y Porcentaje de Regiones",
    x = "Región",
    y = "Frecuencia"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Frecuencia de Tipos de Cultivo **`Crop_Type`**
```{r}
# Crear la tabla de frecuencias y calcular el porcentaje
var_freq <- as.data.frame(table(climate_data$Crop_Type))
colnames(var_freq) <- c("Crop_Type", "Frequency")
var_freq <- var_freq %>%
  mutate(Percentage = (Frequency / sum(Frequency)) * 100)

# Crear la gráfica combinada de frecuencia y porcentaje
ggplot(var_freq, aes(x = reorder(Crop_Type, -Frequency), y = Frequency)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
            vjust = -0.5, size = 3.5, color = "black") +
  theme_minimal() +
  labs(
    title = "Frecuencia y Porcentaje de Tipos de Cultivo",
    x = "Tipo",
    y = "Frecuencia"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Frecuencia de Estrategias de Adaptación **`Adaptation_Strategies`**
```{r}
# Crear la tabla de frecuencias y calcular el porcentaje
var_freq <- as.data.frame(table(climate_data$Adaptation_Strategies))
colnames(var_freq) <- c("Adaptation_Strategies", "Frequency")
var_freq <- var_freq %>%
  mutate(Percentage = (Frequency / sum(Frequency)) * 100)

# Crear la gráfica combinada de frecuencia y porcentaje
ggplot(var_freq, aes(x = reorder(Adaptation_Strategies, -Frequency), y = Frequency)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
            vjust = -0.5, size = 3.5, color = "black") +
  theme_minimal() +
  labs(
    title = "Frecuencia y Porcentaje de Estrategias de Adaptación",
    x = "Estrategia",
    y = "Frecuencia"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Pairwise scatter plots
Los gráficos de dispersión por pares son una herramienta visual poderosa para analizar relaciones entre múltiples variables numéricas. Al graficar cada par de variables en un conjunto de datos, podemos identificar patrones, tendencias, y posibles correlaciones lineales o no lineales entre ellas.

Este enfoque es particularmente útil para:

- Detectar relaciones lineales o no lineales entre variables.
- Evitar multicolinaliedad.
```{r}
numeric_vars <- climate_data[, sapply(climate_data, is.numeric)]
```

Hagamos el plot
```{r}
# Fijar la semilla para reproducibilidad
set.seed(123)

# Seleccionar una muestra aleatoria de 500 filas
sample_size <- 500
climate_data_sample <- numeric_vars[sample(nrow(numeric_vars), sample_size), ]

# Dibujar el gráfico de pares con la muestra
pairs(climate_data_sample, 
      main = "Pares para una Muestra Aleatoria de Datos",
      pch = 19, 
      cex = 0.5, 
      col = rgb(0.2, 0.4, 0.6, 0.6))
```

## Coeficientes empíricos de Pearson
El coeficiente de correlación de Pearson mide la relación lineal entre variables numéricas. Un valor cercano a 1 o -1 indica una fuerte correlación positiva o negativa, respectivamente, mientras que un valor cercano a 0 indica una correlación débil o inexistente.

A continuación, calculamos la matriz de correlaciones para nuestras variables numéricas:
```{r}
# Calcular la matriz de correlaciones
cor_matrix <- cor(numeric_vars, use = "complete.obs")  # Ignorar valores NA

# Convertir la matriz en un formato largo para ggplot
cor_long <- melt(cor_matrix)

# Crear el mapa de calor
ggplot(cor_long, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0,
                       limit = c(-1, 1), space = "Lab", name = "Correlación") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = "Mapa de Calor de Correlaciones (Coeficiente de Pearson)",
    x = "Variables",
    y = "Variables"
  )

```
Observamos que no tenemos problemas de multicolienaliedad entre variables explicatorias excepto en Economic_Impact_Million_USD. Esto lo resolveremos en la sección `Modificación de Datos`.


## Cálculo de Eta Squared para Variables Numéricas y Categóricas

El coeficiente Eta Squared mide la proporción de la varianza explicada de una variable numérica por una variable categórica. Este cálculo es útil para evaluar qué tan fuerte es la relación entre variables categóricas y numéricas en un conjunto de datos.

Un valor de Eta Squared más alto indica que la variable categórica tiene un mayor efecto sobre la variable numérica, mientras que un valor cercano a 0 sugiere que la variable categórica no tiene un efecto significativo.

Este análisis es particularmente valioso para:

- Explorar la fuerza de asociación entre grupos definidos por una categoría y una medida cuantitativa.
- Identificar variables categóricas relevantes para el análisis predictivo o explicativo.

```{r, warning=FALSE, message=FALSE}

# Separar variables numéricas y categóricas
numeric_vars <- climate_data[, sapply(climate_data, is.numeric)]
categorical_vars <- climate_data[, sapply(climate_data, is.character)]

# Función para calcular eta squared
calculate_eta_squared <- function(numeric_col, categorical_col) {
  # Crear un data frame temporal para trabajar
  temp_data <- data.frame(
    numeric_col = numeric_col,
    categorical_col = categorical_col
  )
  # Remover NA para evitar errores
  temp_data <- na.omit(temp_data)
  
  # Calcular eta squared
  model <- aov(numeric_col ~ categorical_col, data = temp_data)
  eta_squared <- eta_squared(model)
  return(eta_squared$Eta2[1]) # Devuelve el eta squared para el efecto principal
}

# Crear un data frame para almacenar los resultados
results <- expand.grid(
  Numeric = colnames(numeric_vars),
  Categorical = colnames(categorical_vars)
) %>%
  rowwise() %>%
  mutate(Eta_Squared = calculate_eta_squared(
    numeric_vars[[Numeric]],
    categorical_vars[[Categorical]]
  )) %>%
  ungroup()

# Mostrar resultados en una tabla ordenada
results <- results %>% arrange(desc(Eta_Squared))
kable(
  results,
  caption = "Resultados de Eta Squared para cada par de variables numéricas y categóricas"
)
```

Vemos que no tenemos problemas de multicolinealiedad entre nuestras variables explicatorias continuas y categoricas.




## Cálculo de Cramér's V para Variables Categóricas

A continuación, se calcula el valor de Cramér's V (\(V\)) para cada combinación posible de dos variables categóricas del dataset.

```{r cramers-v-calculation, warning=FALSE, message=FALSE}
# Seleccionar solo variables categóricas
categorical_vars <- climate_data[, sapply(climate_data, is.character)]

# Función para calcular Cramér's V
calculate_cramers_v <- function(var1, var2) {
  # Crear tabla de contingencia
  contingency_table <- table(var1, var2)
  # Calcular Cramér's V
  cramers_v <- assocstats(contingency_table)$cramer
  return(cramers_v)
}

# Generar combinaciones de todas las variables categóricas
categorical_combinations <- combn(colnames(categorical_vars), 2, simplify = FALSE)

# Calcular Cramér's V para cada combinación
results_cramers_v <- map_dfr(
  categorical_combinations,
  ~ tibble(
    Var1 = .x[1],
    Var2 = .x[2],
    Cramers_V = calculate_cramers_v(categorical_vars[[.x[1]]], categorical_vars[[.x[2]]])
  )
)

# Ordenar resultados por el valor de Cramér's V
results_cramers_v <- results_cramers_v %>% arrange(desc(Cramers_V))
kable(
  results_cramers_v,
  caption = "Resultados de Cramér's V para cada par de variables categóricas"
)
```
Vemos que solo tenemos problemas de multicolinealiedad entre Country y Region, problema que resolveremos en la seeción siguiente. En cuanto a las demas variables categoricas, no tenemos problemas de multicolinealiedad entre ellas.


## Modificaciones a los datos

Como podemos observar, contamos con una amplia variedad de categorías. Para evitar multicolinealida, así como una segmentación excesiva de nuestro conjunto de datos, optaremos por eliminar la variable **`Region`** y agrupar los valores de la variable **`Country`** por continentes.
```{r}
# Elimina 'Region'
climate_data <- climate_data %>% select(-Region)

# Agrupar países en continentes
climate_data$Continent <- countrycode(climate_data$Country, "country.name", "continent")

# Elimina 'Country'
climate_data <- climate_data %>% select(-Country)

```

Eliminaremos la columna **`Year`** del dataset porque su inclusión podría introducir una dependencia temporal que no es el enfoque principal de este análisis.
```{r}
# Elimina 'Year'
climate_data <- climate_data %>% select(-Year)
```


La variable **`Economic_Impact_Million_USD`** representa el impacto económico estimado asociado a la productividad agrícola. Sin embargo, esta métrica se calcula posteriormente a la cosecha, ya que depende directamente de los rendimientos obtenidos y de factores externos como los precios de mercado y las políticas económicas. Por esta razón, no es adecuada para incluirla como predictor en este análisis
```{r}
# Elimina 'Economic_Impact_Million_USD'
climate_data <- climate_data %>% select(-Economic_Impact_Million_USD)
```

Estandarizaremos los datos antes de ajustarlos al modelo. La estandarización transforma las variables numéricas para que tengan media 0 y desviación estándar 1, lo que es especialmente importante cuando las variables tienen diferentes unidades o rangos. Esto permite que el modelo lineal generalizado (GLM) considere todas las variables en una escala comparable, reduciendo el impacto de aquellas con valores más grandes en la estimación de los coeficientes.
```{r}
# Función para estandarizar solo las variables predictoras
standardize_predictors <- function(data, response_var) {
  numeric_cols <- sapply(data, is.numeric)  # Identificar columnas numéricas
  predictors <- numeric_cols & names(data) != response_var  # Excluir la variable objetivo
  data[, predictors] <- scale(data[, predictors])  # Estandarizar solo las predictoras
  return(data)
}

# Aplicar la estandarización al dataset
response_var <- "Crop_Yield_MT_per_HA"  # Nombre de la variable objetivo
climate_data <- standardize_predictors(climate_data, response_var)
```



## Modelos
El histograma de la variable Crop_Yield_MT_per_HA muestra una distribución asimétrica positiva, lo que indica que los datos no son normales y están mejor representados por una distribución perteneciente a la familia exponencial, como la distribución gamma. Dado este comportamiento, utilizaremos un modelo lineal generalizado (GLM) con una distribución gamma para modelar esta variable.


En el modelo ajustado, la variable \( Y \) (productividad agrícola, \texttt{Crop\_Yield\_MT\_per\_HA}) se asume que sigue una \textbf{distribución Gamma}. Su distribución puede expresarse de la siguiente manera:

\[
Y_i \sim \text{Gamma}(\alpha, \beta)
\]

La forma general de la familia exponencial para esta Gamma es:

\[
f(y; \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} y^{\alpha - 1} e^{-\beta y}, \quad y > 0,
\]

donde identificamos los términos de la forma de la familia exponencial:
\begin{itemize}
    \item El parámetro natural es \( \theta = -\beta \),
    \item El parámetro de dispersión es \( \phi = 1 \),
    \item La función log-partición es \( b(\theta) = -\alpha \log(-\theta) \), donde \( -\theta = \beta \),
    \item La función base es \( c(y; \phi) = (\alpha - 1) \log y - \log \Gamma(\alpha) \).
\end{itemize}

y tenemos que  

\[
\mathbb{E}[Y] = b'(\theta) = \mu = g^{-1}(\eta)
\]

\[
\text{Var}(Y) = \phi b''(\theta) = \phi V(\mu) = \phi V(g^{-1}(\eta))
\]

donde \( \eta = \mathbf{X} \boldsymbol{\beta} \) y \( V(\cdot) \) es la función de varianza, \( g() \) es la función liga, \(\mathbf{X}\) es la matriz diseño y \( \boldsymbol{\beta} \) el vector de coeficientes.


Comenzamos planteando un modelo con la siguiente liga y definición de \( \eta \):

\[
\boldsymbol{\beta} \in \mathbb{R}^{26}, \quad \mathbf{X} \in \mathbb{R}^{10000 \times 26}, \eta \in \mathbb{R}^{10000}
\]


\begin{align*}
\eta_i &= \beta_0 
+ \beta_1 \cdot D_{\text{Crop\_TypeCoffee}}(i) 
+ \beta_2 \cdot D_{\text{Crop\_TypeCorn}}(i) + \beta_3 \cdot D_{\text{Crop\_TypeCotton}}(i) + \beta_4 \cdot D_{\text{Crop\_TypeFruits}}(i) \\
&+ \beta_5 \cdot D_{\text{Crop\_TypeRice}}(i) 
+ \beta_6 \cdot D_{\text{Crop\_TypeSoybeans}}(i) 
+ \beta_7 \cdot D_{\text{Crop\_TypeSugarcane}}(i) 
+ \beta_8 \cdot D_{\text{Crop\_TypeVegetables}}(i) \\
&+ \beta_9 \cdot D_{\text{Crop\_TypeWheat}}(i) 
+ \beta_{10} \cdot \text{Average\_Temperature\_C}_i 
+ \beta_{11} \cdot \text{Total\_Precipitation\_mm}_i \\
&+ \beta_{12} \cdot \text{CO2\_Emissions\_MT}_i 
+ \beta_{13} \cdot \text{Extreme\_Weather\_Events}_i 
+ \beta_{14} \cdot \text{Irrigation\_Access\_}_i \\
&+ \beta_{15} \cdot \text{Pesticide\_Use\_KG\_per\_HA}_i 
+ \beta_{16} \cdot \text{Fertilizer\_Use\_KG\_per\_HA}_i 
+ \beta_{17} \cdot \text{Soil\_Health\_Index}_i \\
&+ \beta_{18} \cdot D_{\text{Adaptation\_StrategiesDrought-resistant\_Crops}}(i) 
+ \beta_{19} \cdot D_{\text{Adaptation\_StrategiesNo\_Adaptation}}(i) \\
&+ \beta_{20} \cdot D_{\text{Adaptation\_StrategiesOrganic\_Farming}}(i)
+ \beta_{21} \cdot D_{\text{Adaptation\_StrategiesWater\_Management}}(i) 
+ \beta_{22} \cdot D_{\text{ContinentAmericas}}(i) \\
&+ \beta_{23} \cdot D_{\text{ContinentAsia}}(i)
+ \beta_{24} \cdot D_{\text{ContinentEurope}}(i) 
+ \beta_{25} \cdot D_{\text{ContinentOceania}}(i).
\end{align*}

\[
g(\mu) = \log(\mu), \quad \text{donde } g(\cdot) \text{ es la función liga log.}
\]

Por lo que

\[ \mathbb{E}[Y_i] =  \mu_i = e^{\eta_i}\]




Ajustamos dicho modelo
```{r}
# Ajustar el modelo GLM con enlace logarítmico
glm_log <- glm(
  Crop_Yield_MT_per_HA ~ ., 
  data = climate_data, 
  family = Gamma(link = "log")
)
```


Inicialmente, empleamos una función liga logarítmica (log). Ahora, también exploraremos el uso de la función de enlace inversa (inverse).


\[
g(\mu) = \frac{1}{\mu}
\]

Por lo que

\[ \mathbb{E}[Y_i] =  \mu_i = \frac{1}{\eta_i}\]

Ajustamos

```{r}
# Ajustar el modelo GLM con enlace inverso
glm_inverse <- glm(
  Crop_Yield_MT_per_HA ~ ., 
  data = climate_data, 
  family = Gamma(link = "inverse")
)
```




Planteamos adicionalmente dos modelos reducidos con la siguiente definición de \( X, \eta \)

\[
\boldsymbol{\beta} \in \mathbb{R}^{13}, \quad \mathbf{X} \in \mathbb{R}^{10000 \times 13}, \eta \in \mathbb{R}^{10000}
\]

\begin{align*}
\eta_i &= \beta_0 
+ \beta_{1} \cdot \text{Average\_Temperature\_C}_i 
+ \beta_{2} \cdot \text{CO2\_Emissions\_MT}_i 
+ \beta_{3} \cdot \text{Total\_Precipitation\_mm}_i \\
&+ \beta_4 \cdot D_{\text{Crop\_TypeCoffee}}(i) 
+ \beta_5 \cdot D_{\text{Crop\_TypeCorn}}(i) 
+ \beta_6 \cdot D_{\text{Crop\_TypeCotton}}(i) 
+ \beta_7 \cdot D_{\text{Crop\_TypeFruits}}(i) \\
&+ \beta_8 \cdot D_{\text{Crop\_TypeRice}}(i) 
+ \beta_9 \cdot D_{\text{Crop\_TypeSoybeans}}(i) 
+ \beta_{10} \cdot D_{\text{Crop\_TypeSugarcane}}(i) 
+ \beta_{11} \cdot D_{\text{Crop\_TypeVegetables}}(i) \\
&+ \beta_{12} \cdot D_{\text{Crop\_TypeWheat}}(i) 
\end{align*}


En el primer modelo
\[
g(\mu) = \log(\mu), \quad \text{donde } g(\cdot) \text{ es la función liga log.}
\]

Por lo que

\[ \mathbb{E}[Y_i] =  \mu_i = e^{\eta_i}\]

Ajustamos

```{r}
# Ajustar el modelo reducido GLM con enlace logaritmico
glm_log.red <- glm(
  Crop_Yield_MT_per_HA ~ Average_Temperature_C + CO2_Emissions_MT + Total_Precipitation_mm  + Crop_Type, 
  data = climate_data, 
  family = Gamma(link = "log")
)
```

En el segundo
\[
g(\mu) = \frac{1}{\mu}
\]

Por lo que

\[ \mathbb{E}[Y_i] =  \mu_i = \frac{1}{\eta_i}\]

Ajustamos
```{r}
# Ajustar el modelo reducido GLM con enlace inverso
glm_inverse.red <- glm(
  Crop_Yield_MT_per_HA ~ Average_Temperature_C + CO2_Emissions_MT + Total_Precipitation_mm  + Crop_Type, 
  data = climate_data, 
  family = Gamma(link = "inverse")
)
```



## Bondad de Ajuste

La bondad de ajuste también implica verificar que el modelo cumple con los supuestos teóricos bajo los cuales se construyó. 
En el caso de un modelo lineal generalizado (GLM) con distribución gamma y enlace logarítmico, es importante asegurarse de que:

\begin{enumerate}
    \item \textbf{La dispersión residual} es razonable y consistente con los supuestos.
    \item \textbf{El enlace logarítmico} es adecuado para relacionar las variables predictoras con la variable objetivo.
    \item \textbf{No existen valores atípicos extremos} que influyan de manera desproporcionada en el modelo.
\end{enumerate}

A continuación, verificaremos estos aspectos mediante visualizaciones y métricas clave para asegurar que el modelo respeta sus supuestos fundamentales. 
Esto es crucial para garantizar la validez de las inferencias y predicciones derivadas del modelo.



### Investigación de Residuos

\begin{enumerate}
    \item Los \textbf{residuos de Pearson} verifican si la varianza está correctamente especificada. Estos deben estar centrados en 0 y tener una varianza aproximada de 1.
    \item Los \textbf{residuos de Deviance} verifican si la función de enlace g() es apropiada. Si hay valores grandes en los residuos de deviance, podría ser que el enlace no sea correcto.
\end{enumerate}


```{r, echo=TRUE, results='hide', fig.show="hide"}
# Función para crear gráficos de residuos vs predictor lineal
create_residual_vs_linear_predictor <- function(model, model_name) {
  # Residuos de Pearson
  pearson_residuals <- residuals(model, type = "pearson")
  linear_predictor <- predict(model, type = "link")  # Predictor lineal
  
  scatter_pearson <- ggplot() +
    aes(x = linear_predictor, y = pearson_residuals) +
    geom_point(alpha = 0.5) +
    geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
    labs(title = paste("Residuos de Pearson -", model_name), 
         x = "Predictor Lineal (\u03B7)", 
         y = "Residuos de Pearson") +
    theme_minimal()
  
  # Residuos de Deviance
  deviance_residuals <- residuals(model, type = "deviance")
  
  scatter_deviance <- ggplot() +
    aes(x = linear_predictor, y = deviance_residuals) +
    geom_point(alpha = 0.5) +
    labs(title = paste("Residuos de Deviance -", model_name), 
         x = "Predictor Lineal (\u03B7)", 
         y = "Residuos de Deviance") +
    theme_minimal()
  
  return(list(scatter_pearson, scatter_deviance))
}

# Crear las gráficas para cada modelo
plots_log <- create_residual_vs_linear_predictor(glm_log, "Log")
plots_inverse <- create_residual_vs_linear_predictor(glm_inverse, "Inverse")
plots_log_red <- create_residual_vs_linear_predictor(glm_log.red, "Log Reducido")
plots_inverse_red <- create_residual_vs_linear_predictor(glm_inverse.red, "Inverse Reducido")

# Combinar todas las gráficas en una sola lista
all_plots <- c(
  plots_log, 
  plots_inverse, 
  plots_log_red, 
  plots_inverse_red
)

# Crear una salida de dimensiones más grandes para que las gráficas no se vean aplastadas
ggsave(
  filename = "residual_plots_grid.png",  # Guardar como imagen
  plot = grid.arrange(
    grobs = all_plots,
    nrow = 4,
    ncol = 2,
    top = "Comparación de Residuos para los Modelos",
    heights = unit(c(1, 1, 1, 1), "null"),  # Ajustar proporciones para filas
    widths = unit(c(1, 1), "null")          # Ajustar proporciones para columnas
  ),
  width = 12,  # Ancho total en pulgadas
  height = 16  # Alto total en pulgadas
)
```
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{residual_plots_grid.png}
\caption{Comparación de Residuos.}
\label{fig:residual-plots}
\end{figure}

En nuestra investigación de residuos (Pearson y Deviance) **Figura \ref{fig:residual-plots}** , encontramos que, en general, los residuos se comportan como se espera, mostrando una distribución aproximadamente centrada en cero con varianza constante, lo cual es consistente con los supuestos del modelo. Sin embargo, identificamos un pico inusual en los residuos hacia la mitad de los datos, lo que podría indicar la presencia de patrones no explicados completamente por el modelo. Resolver este problema requeriría un análisis más profundo y complejo con técnicas y conceptopsque quedan fuera del alcance de este curso. Por lo tanto, procederemos con los modelos actuales, conscientes de esta limitación.


### Valores Atípicos

En esta sección, nos enfocaremos en la detección de valores atípicos (\textit{outliers}) que podrían estar influyendo de manera significativa en los resultados de nuestros modelos. Identificar y manejar estos valores es crucial para garantizar la robustez y confiabilidad de las estimaciones.

Para ello, utilizaremos tres representaciones (gráficas y estadísticas) clave:
\begin{enumerate}
    \item \textbf{Leverage}: Nos permite identificar observaciones con un alto impacto en la estimación de los coeficientes debido a su posición en el espacio de las variables predictoras.
    \item \textbf{Distancia de Cook}: Evalúa la influencia combinada de leverage y residuos en la calidad del ajuste del modelo. Valores altos indican observaciones con un impacto significativo en las predicciones.
    \item \textbf{Gráfico Leverage vs Distancia de Cook}: Combina ambas métricas para proporcionar una visión completa de las observaciones influyentes.
\end{enumerate}

Con base en estas visualizaciones, identificaremos las observaciones que representen valores atípicos y procederemos a eliminarlas del conjunto de datos para asegurar un análisis más preciso y representativo. Este proceso nos permitirá ajustar modelos que reflejen de manera más fiel las tendencias y patrones en los datos.


Calculemos los outliers
```{r}
# Función para calcular leverage y distancia de Cook
detect_outliers <- function(model, model_name) {
  leverage <- hatvalues(model)
  cook_distance <- cooks.distance(model)
  
  # Umbrales
  threshold_leverage <- 2 * mean(leverage)  # Umbral para leverage
  threshold_cook <- 1  # Umbral fijo para Cook's distance
  
  # Identificar outliers
  leverage_outliers <- which(leverage > threshold_leverage)
  cook_outliers <- which(cook_distance > threshold_cook)
  
  # Combinar resultados
  all_outliers <- unique(c(leverage_outliers, cook_outliers))
  
  # Manejo de casos donde no hay outliers
  if (length(leverage_outliers) == 0) {
    leverage_outliers <- "Ninguno"
  }
  if (length(cook_outliers) == 0) {
    cook_outliers <- "Ninguno"
  }
  if (length(all_outliers) == 0) {
    all_outliers <- "Ninguno"
  }
  
  # Total de outliers
  total_leverage <- if (is.numeric(leverage_outliers)) length(leverage_outliers) else 0
  total_cook <- if (is.numeric(cook_outliers)) length(cook_outliers) else 0
  total_all <- if (is.numeric(all_outliers)) length(all_outliers) else 0
  
  # Resultados
  list(
    modelo = model_name,
    threshold_leverage = threshold_leverage,
    threshold_cook = threshold_cook,
    leverage_outliers = leverage_outliers,
    cook_outliers = cook_outliers,
    all_outliers = all_outliers,
    total_leverage = total_leverage,
    total_cook = total_cook,
    total_all = total_all
  )
}

# Aplicar la función a los 4 modelos
outliers_log <- detect_outliers(glm_log, "Log")
outliers_inverse <- detect_outliers(glm_inverse, "Inverse")
outliers_log_red <- detect_outliers(glm_log.red, "Log Reducido")
outliers_inverse_red <- detect_outliers(glm_inverse.red, "Inverse Reducido")

# Mostrar resultados de cada modelo
resultados <- list(outliers_log, outliers_inverse, outliers_log_red, outliers_inverse_red)

for (res in resultados) {
  cat("\n--- Modelo:", res$modelo, "---\n")
  cat("Umbral de Leverage:", res$threshold_leverage, "\n")
  cat("Umbral de Cook:", res$threshold_cook, "\n")
  cat("Total de Outliers por Leverage:", res$total_leverage, "\n")
  cat("Total de Outliers por Cook:", res$total_cook, "\n")
  cat("Total de Outliers combinados:", res$total_all, "\n")
}

# Obtener el total de índices únicos de outliers combinados
unique_outliers <- unique(c(
  if (is.numeric(outliers_log$all_outliers)) outliers_log$all_outliers else numeric(0),
  if (is.numeric(outliers_inverse$all_outliers)) outliers_inverse$all_outliers else numeric(0),
  if (is.numeric(outliers_log_red$all_outliers)) outliers_log_red$all_outliers else numeric(0),
  if (is.numeric(outliers_inverse_red$all_outliers)) outliers_inverse_red$all_outliers else numeric(0)
))

# Imprimir el total de índices únicos de outliers
cat("\n--- Resumen General ---\n")
cat("Total de índices únicos de outliers combinados:", length(unique_outliers), "\n")
```

Grafiquemos Leverage
```{r}
# Función para graficar leverage
plot_leverage <- function(model, model_name) {
  # Calcular leverage
  leverage <- hatvalues(model)
  
  # Umbral de leverage
  threshold_leverage <- 2 * mean(leverage)
  
  # Crear el gráfico
  plot(
    leverage,
    main = paste("Gráfico de Leverage -", model_name),
    xlab = "Índice de Observación",
    ylab = "Leverage",
    pch = 19, col = ifelse(leverage > threshold_leverage, "red", "blue")
  )
  
  # Añadir línea del umbral
  abline(h = threshold_leverage, col = "red", lty = 2)
  
  # Añadir leyenda
  legend(
    "topright", 
    legend = c("Por Encima del Umbral", "Por Debajo del Umbral"),
    col = c("red", "blue"), 
    pch = 19, 
    bty = "n"
  )
}

# Crear las gráficas para los 4 modelos
par(mfrow = c(2, 2))  # Configurar una cuadrícula de 2x2
plot_leverage(glm_log, "Log")
plot_leverage(glm_inverse, "Inverse")
plot_leverage(glm_log.red, "Log Reducido")
plot_leverage(glm_inverse.red, "Inverse Reducido")
```

Grafiquemos Distancia de Cook

```{r}
# Función para graficar distancia de Cook
plot_cooks_distance <- function(model, model_name) {
  # Calcular distancia de Cook
  cook_distance <- cooks.distance(model)
  
  # Umbral de Cook
  threshold_cook <- 1  # Umbral fijo
  
  # Crear el gráfico
  plot(
    cook_distance,
    main = paste("Gráfico de Distancia de Cook -", model_name),
    xlab = "Índice de Observación",
    ylab = "Distancia de Cook",
    pch = 19, col = ifelse(cook_distance > threshold_cook, "red", "blue")
  )
  
  # Añadir línea del umbral
  abline(h = threshold_cook, col = "red", lty = 2)
  
  # Añadir leyenda
  legend(
    "topright", 
    legend = c("Por Encima del Umbral", "Por Debajo del Umbral"),
    col = c("red", "blue"), 
    pch = 19, 
    bty = "n"
  )
}

# Crear las gráficas para los 4 modelos
par(mfrow = c(2, 2))  # Configurar una cuadrícula de 2x2
plot_cooks_distance(glm_log, "Log")
plot_cooks_distance(glm_inverse, "Inverse")
plot_cooks_distance(glm_log.red, "Log Reducido")
plot_cooks_distance(glm_inverse.red, "Inverse Reducido")


```



Ahora graficaremos Leverage vs. Distancia de Cook

```{r}
# Función para graficar leverage vs Cook's distance
plot_leverage_cook <- function(model, model_name) {
  leverage <- hatvalues(model)  # Calcular leverage
  cook_distance <- cooks.distance(model)  # Calcular distancia de Cook
  
  # Umbrales
  threshold_leverage <- 2 * mean(leverage)
  threshold_cook <- 1
  
  # Crear el gráfico
  plot(
    leverage, cook_distance, 
    main = paste("Leverage vs Distancia de Cook -", model_name),
    xlab = "Leverage",
    ylab = "Distancia de Cook",
    pch = 19, col = ifelse(leverage > threshold_leverage | cook_distance > threshold_cook, "red", "black")
  )
  
  # Añadir líneas de umbral
  abline(v = threshold_leverage, col = "blue", lty = 2)
  abline(h = threshold_cook, col = "blue", lty = 2)
  
  # Leyenda
  legend(
    "topright", legend = c("Atípico", "Normal"),
    col = c("red", "black"), pch = 19, bty = "n"
  )
}

# Crear las gráficas para los 4 modelos
par(mfrow = c(2, 2))  # Configurar una cuadrícula de 2x2 para las gráficas
plot_leverage_cook(glm_log, "Log")
plot_leverage_cook(glm_inverse, "Inverse")
plot_leverage_cook(glm_log.red, "Log Reducido")
plot_leverage_cook(glm_inverse.red, "Inverse Reducido")
```


En nuestra base de datos de 10,000 observaciones, identificamos 80 valores atípicos a través de los cuatro modelos. Estos outliers representan el 0.8% del total de los datos. Dado que pueden afectar al ajuste de nuestro modelo de manera desproporcionada y, considerando su bajo porcentaje, procedemos a eliminarlos.

```{r}
# Función para eliminar outliers del dataset
remove_outliers <- function(data, outliers_indices) {
  # Verificar si los índices de outliers son válidos
  if (length(outliers_indices) == 0) {
    return(data)  # Devolver el dataset original si no hay outliers
  }
  # Excluir las filas identificadas como outliers
  data_clean <- data[-outliers_indices, ]
  return(data_clean)
}

# Verificar y combinar los índices de outliers
outliers_combined <- unique(c(
  if (is.numeric(outliers_log$all_outliers)) outliers_log$all_outliers else numeric(0),
  if (is.numeric(outliers_inverse$all_outliers)) outliers_inverse$all_outliers else numeric(0),
  if (is.numeric(outliers_log_red$all_outliers)) outliers_log_red$all_outliers else numeric(0),
  if (is.numeric(outliers_inverse_red$all_outliers)) outliers_inverse_red$all_outliers else numeric(0)
))

# Crear un nuevo dataset sin outliers
climate_data_clean <- remove_outliers(climate_data, outliers_combined)

# Mostrar el número de observaciones antes y después
cat("Número de observaciones antes de eliminar outliers:", nrow(climate_data), "\n")
cat("Número de observaciones después de eliminar outliers:", nrow(climate_data_clean), "\n")
cat("Total de outliers eliminados:", length(outliers_combined), "\n")

```

Volvemos a ajustar con datasets sin outliers

```{r}
# Ajustamos
glm_log_clean <- glm(
  Crop_Yield_MT_per_HA ~ ., 
  data = climate_data_clean, 
  family = Gamma(link = "log")
)

glm_inverse_clean <- glm(
  Crop_Yield_MT_per_HA ~ ., 
  data = climate_data_clean, 
  family = Gamma(link = "inverse")
)

glm_log_red_clean <- glm(
  Crop_Yield_MT_per_HA ~ Average_Temperature_C + CO2_Emissions_MT + Total_Precipitation_mm + Crop_Type, 
  data = climate_data_clean, 
  family = Gamma(link = "log")
)

glm_inverse_red_clean <- glm(
  Crop_Yield_MT_per_HA ~ Average_Temperature_C + CO2_Emissions_MT + Total_Precipitation_mm + Crop_Type, 
  data = climate_data_clean, 
  family = Gamma(link = "inverse")
)
```


## Comparación de modelos

En esta sección, evaluaremos y compararemos los cuatro modelos ajustados utilizando diversas métricas de desempeño y técnicas de contraste. Para identificar el modelo que mejor se ajusta a nuestros datos, analizaremos el \textbf{AIC} (Criterio de Información de Akaike) y el \textbf{BIC} (Criterio de Información Bayesiano), que penalizan la complejidad del modelo en favor de su simplicidad. También incluiremos la \textbf{pseudo \(R^2\)} de McFadden como una medida relativa de la calidad del ajuste, proporcionando una visión general de la capacidad explicativa de cada modelo.

Adicionalmente, compararemos los modelos reducidos con sus modelos padres a través de dos pruebas estadísticas para modelos anidados: la \textbf{Prueba de Razón de Verosimilitudes (LRT)} y el \textbf{Deviance Test}, que nos permitirán evaluar si los modelos reducidos son significativamente peores que sus contrapartes completas o si la reducción es válida sin pérdida sustancial de información. Este análisis integral nos ayudará a seleccionar el modelo más adecuado desde una perspectiva tanto estadística como práctica.



### Comparaciónes con AIC, BIC y \textbf{pseudo \(R^2\)}

```{r}
# Función para calcular la pseudo R^2 (McFadden's R^2)
calculate_pseudo_r2 <- function(model) {
  null_deviance <- model$null.deviance
  residual_deviance <- model$deviance
  pseudo_r2 <- 1 - (residual_deviance / null_deviance)
  return(pseudo_r2)
}

# Crear una lista con los modelos refitteados
models <- list(
  Log = glm_log_clean,
  Inverse = glm_inverse_clean,
  Log_Reducido = glm_log_red_clean,
  Inverse_Reducido = glm_inverse_red_clean
)

# Calcular AIC, BIC y pseudo R^2 para cada modelo
comparison <- data.frame(
  Modelo = names(models),
  AIC = sapply(models, AIC),
  BIC = sapply(models, BIC),
  Pseudo_R2 = sapply(models, calculate_pseudo_r2)
)

# Ordenar por AIC
comparison <- comparison[order(comparison$AIC), ]

# Mostrar la tabla comparativa
print(comparison)

```

El modelo Log Reducido tiene el menor AIC (26824.27), lo que sugiere que es el modelo que mejor predice sin aumentar demasiado su complejidad. El modelo Log Reducido tiene el menor BIC (26925.10), lo que lo hace el preferible si lo que se busca es un modelo más general que preciso.El modelo Log tiene el mayor pseudo \(R^2\) (0.0798), lo que significa que explica ligeramente más variabilidad en los datos que los otros modelos.



### Comparaciones anidadas

```{r}
# Función para realizar las pruebas y formatear resultados en texto
nested_model_tests_text <- function(full_model, reduced_model, model_name) {
  # Prueba de Razón de Verosimilitudes (LRT)
  lrt <- anova(reduced_model, full_model, test = "LRT")
  
  # Deviance Test
  deviance_diff <- reduced_model$deviance - full_model$deviance
  df_diff <- reduced_model$df.residual - full_model$df.residual
  p_value_deviance <- pchisq(deviance_diff, df = abs(df_diff), lower.tail = FALSE)
  
  # Formatear y mostrar resultados
  cat("\n\n\n--- Comparación de Modelos (", model_name, ") ---\n", sep = "")
  
  cat("\nPrueba de Razón de Verosimilitudes (LRT):\n")
  cat("  - Grados de libertad residuales (reducido): ", reduced_model$df.residual, "\n")
  cat("  - Grados de libertad residuales (completo): ", full_model$df.residual, "\n")
  cat("  - Deviancia residual (reducido): ", round(reduced_model$deviance, 2), "\n")
  cat("  - Deviancia residual (completo): ", round(full_model$deviance, 2), "\n")
  cat("  - Diferencia de chi-cuadrado: ", round(lrt[2, "Deviance"], 2), "\n")
  cat("  - P-valor: ", format.pval(lrt[2, "Pr(>Chi)"]), "\n")
  
  cat("\nPrueba de Deviancia:\n")
  cat("  - Diferencia de deviancia: ", round(deviance_diff, 2), "\n")
  cat("  - Diferencia de grados de libertad: ", abs(df_diff), "\n")
  cat("  - P-valor: ", format.pval(p_value_deviance), "\n")
}

# Comparar modelos completos vs reducidos
nested_model_tests_text(glm_log_clean, glm_log_red_clean, "Modelo Log")
nested_model_tests_text(glm_inverse_clean, glm_inverse_red_clean, "Modelo Inverse")

```

Los resultados de las pruebas de comparación entre los modelos completos y reducidos muestran valores \(p\) altos (\(p > 0.05\)) en ambas pruebas, indicando que no hay evidencia estadística suficiente para rechazar la hipótesis nula. Esto sugiere que los modelos reducidos ofrecen un ajuste comparable al de los modelos completos, por lo que podemos utilizarlos sin pérdida significativa de información.


### Cross validation

En esta sección, realizamos un análisis de validación cruzada para evaluar el desempeño predictivo de los modelos ajustados. Utilizamos un esquema de \textbf{10 folds} repetido \textbf{100 veces} para obtener una medida confiable de la deviancia promedio. La \textit{deviancia total} se calcula como una métrica que evalúa qué tan bien cada modelo ajusta los datos observados, penalizando las discrepancias entre los valores predichos y los reales.


```{r, message=FALSE, warning=FALSE}
# Definir la función de deviance gamma
gamma_deviance <- function(y, mu) {
  return(2 * sum(((y - mu) / mu) - log(y / mu)))
}

# Realizar validación cruzada usando cv.glm
perform_cv_glm <- function(model, data, k_folds = 10) {
  set.seed(456)  # Semilla para reproducibilidad
  
  # Validación cruzada con cv.glm
  cv_results <- cv.glm(
    data = data,
    glmfit = model,
    cost = gamma_deviance,  # Utilizamos la deviance gamma como métrica
    K = k_folds
  )
  
  # Retornar el costo (Deviance)
  return(cv_results$delta[1])  # delta[1] es el error
}

# Aplicar validación cruzada a cada modelo
cv_deviance_results <- data.frame(
  Modelo = c("Log", "Log Reducido", "Inverse", "Inverse Reducido"),
  Deviance = c(
    perform_cv_glm(glm_log_clean, climate_data_clean),
    perform_cv_glm(glm_log_red_clean, climate_data_clean),
    perform_cv_glm(glm_inverse_clean, climate_data_clean),
    perform_cv_glm(glm_inverse_red_clean, climate_data_clean)
  )
)

# Mostrar resultados
print(cv_deviance_results)
```

El modelo Log Reducido tiene, en promedio, un Deviance menor al evaular el modelo, lo que indica que es el modelo que ofrece el mejor ajuste para nuestros datos. Los modelos con enlace inverso presentan un peor desempeño (mayor deviance). Los modelos reducidos presentan un mejor desempeño que sus contrapartes (modelos completos).



## Pruebas sobre coeficientes

Primero, evaluaremos la significancia estadística de los coeficientes estimados en los modelos ajustados. Esto nos permitirá identificar cuáles variables tienen un impacto significativo en la variable de respuesta y cuáles podrían considerarse irrelevantes. Para ello, utilizaremos pruebas z (asintoticamente) expuestas en el summary del fit, donde la hipótesis nula establece que el coeficiente es igual a cero (\(H_0: \beta_i = 0\)). Este análisis nos ayudará a comprender mejor las relaciones entre las variables predictoras y la productividad agrícola, y a justificar la inclusión o exclusión de variables en los modelos reducidos.


```{r}

cat("\n--- Summary de modelo con liga log ---\n", sep = "")
summary(glm_log_clean)
cat("\n\n--- Summary de modelo con liga inv ---\n", sep = "")
summary(glm_inverse_clean)
cat("\n\n--- Summary de modelo reducido con liga log ---\n", sep = "")
summary(glm_log_red_clean)
cat("\n\n--- Summary de modelo reducido con liga inv ---\n", sep = "")
summary(glm_inverse_red_clean)
```




# Interpretación de Resultados

## Datos Faltantes

No se encontraron datos faltantes en el dataset, lo que refuerza la confiabilidad de los análisis realizados. Esto elimina la necesidad de realizar imputaciones, preservando la integridad de las relaciones entre variables.

## Variables Numéricas

### Productividad Agrícola
La distribución muestra asimetría positiva, con la mayoría de los cultivos presentando rendimientos bajos (alrededor de 1-2 toneladas por hectárea) y un número reducido con rendimientos altos (hasta 5 toneladas por hectárea). Esto sugiere que la productividad agrícola sigue una tendencia donde los factores climáticos y de manejo tienen un impacto considerable, aunque solo algunos sistemas agrícolas logran maximizar el rendimiento.

### Temperatura Promedio
La distribución bimodal indica que el dataset incluye regiones con climas predominantemente fríos y cálidos, con picos en temperaturas promedio de 10°C y 25°C. Esto podría reflejar zonas templadas y tropicales, respectivamente. Los valores extremos sugieren regiones con condiciones climáticas inusuales, lo que podría afectar significativamente el rendimiento.

### Precipitación Total
Aunque la mayoría de las regiones reciben precipitaciones moderadas (500-1000 mm), algunas áreas muestran lluvias excepcionalmente altas (>2500 mm), asociadas probablemente con zonas tropicales o eventos extremos como inundaciones.

### Eventos Climáticos Extremos
El bajo número de eventos extremos en la mayoría de las observaciones (0-5) indica que no todas las regiones enfrentan riesgos climáticos severos. Sin embargo, las pocas regiones con más de 5 eventos anuales destacan como áreas de alta vulnerabilidad climática.

### Uso de Pesticidas y Fertilizantes
El uso moderado de pesticidas y fertilizantes en la mayoría de las regiones indica una agricultura menos intensiva químicamente, pero los valores más altos sugieren prácticas intensivas en cultivos específicos o regiones con problemas de plagas y suelos menos fértiles.

### Índice de Salud del Suelo
El índice centrado en valores altos (70-80) refleja una buena calidad general del suelo en el dataset. Sin embargo, las regiones con valores más bajos podrían requerir estrategias específicas de manejo del suelo para mejorar la productividad.

## Variables Categóricas

### Países y Regiones
La representatividad equilibrada entre países y regiones asegura que los resultados sean aplicables globalmente. Sin embargo, regiones como el sur de Asia y Europa parecen estar más representadas, lo que podría sesgar algunas observaciones.

### Tipos de Cultivo
La distribución homogénea entre cultivos principales (trigo, arroz, maíz) sugiere que los resultados son relevantes para los cultivos clave en la seguridad alimentaria mundial. Los cultivos menos representados, como el café, podrían requerir análisis específicos.

### Estrategias de Adaptación
La preferencia por la gestión de agua y la rotación de cultivos como estrategias de adaptación destaca la importancia del manejo eficiente de recursos frente a riesgos climáticos.

## Relaciones entre Variables (Gráficos de Pares y Matriz de Correlación)

Los gráficos de dispersión revelaron correlaciones positivas entre la temperatura promedio y la productividad agrícola, hasta cierto umbral (~25°C), más allá del cual la productividad disminuye, indicando un efecto negativo de climas excesivamente cálidos. La precipitación también mostró una relación no lineal, con precipitaciones muy bajas o excesivas reduciendo el rendimiento.

La matriz de correlación indicó relaciones moderadas, sin multicolinealidad significativa entre las variables predictoras, lo que asegura la estabilidad de los modelos ajustados.

## Modelos Generales y Reducidos

Se ajustaron cuatro modelos GLM, dos completos y dos reducidos, utilizando funciones de enlace logarítmico e inverso. El modelo reducido con enlace logarítmico mostró el mejor desempeño según AIC (26824.27) y BIC (26925.10), lo que indica que logra un equilibrio óptimo entre precisión y simplicidad. Este modelo resalta que los factores más significativos para predecir la productividad agrícola son la temperatura promedio, la precipitación total y el tipo de cultivo.

## Bondad de Ajuste y Residuos

Los residuos de Pearson y Deviance confirmaron que los supuestos del modelo (distribución Gamma y enlace logarítmico) son apropiados. Aunque se identificaron patrones residuales no explicados completamente, estos representan una pequeña fracción del conjunto de datos y no comprometen las conclusiones. Estos patrones no explicados pueden derivarse de un llenado (llenar con media ponderada) de la base de datos.

## Eliminación de Outliers

La detección de 80 valores atípicos (0.8\% del dataset) mediante leverage y distancia de Cook permitió ajustar los modelos sin influencias desproporcionadas. Esto mejoró la precisión de las inferencias.

## Comparación y Selección de Modelos

El análisis comparativo mostró que el modelo reducido con enlace logarítmico es el más adecuado para explicar y predecir la productividad agrícola. Aunque el modelo completo ofrece una ligera mejora en el pseudo $R^2$ (0.0798 frente a 0.0788), esta diferencia es marginal y no justifica su mayor complejidad.





# Conclusiones

Este análisis demuestra que la productividad agrícola está influenciada significativamente por factores climáticos y ambientales, siendo la temperatura promedio, la precipitación total y el tipo de cultivo los predictores más relevantes. El modelo reducido con enlace logarítmico ofrece la mejor combinación de precisión predictiva y simplicidad, destacándose como una herramienta eficiente para modelar la relación entre condiciones ambientales y rendimiento agrícola.

Los hallazgos tienen implicaciones prácticas para la toma de decisiones en políticas agrícolas y manejo sostenible. Estrategias como la optimización del riego y la implementación de cultivos resistentes al clima podrían ser fundamentales para mitigar los efectos adversos del cambio climático.

Sin embargo, las limitaciones incluyen la falta de exploración de interacciones complejas entre factores y posibles sesgos geográficos en los datos. Estudios futuros podrían incorporar modelos no lineales más sofisticados o análisis regionales detallados para comprender mejor las dinámicas locales.

En resumen, este proyecto valida el uso de modelos estadísticos para identificar y cuantificar los efectos del clima en la productividad agrícola, ofreciendo \textit{insights} valiosos para un futuro más resiliente en la seguridad alimentaria.



# Referencias

\begin{enumerate}
    \item Vélez and Correa. "Comparación de procedimientos FDR para la selección de parámetros en Regresión Poisson." \textit{Comunicaciones en estadística} (2013). doi:10.15332/s2027-3355.2013.0001.03.
    \item Canales and Arana. "Estimación de la biomasa de langostino amarillo (\textit{Cervimunida johni}), aplicando Modelo Lineal Generalizado a registros de captura por área barrida en la zona central de Chile." \textit{Latin American Journal of Aquatic Research} (2012). doi:10.3856/vol40-issue2-fulltext-7.
    \item Castillo-Badilla. "Factores del animal y el manejo predestete que afectan la edad al primer parto en hatos de lechería especializada de Costa Rica." \textit{Agronomía costarricense} (2019). doi:10.15517/rac.v43i2.37788.
    \item Oddi. "Cuando la variabilidad varía: Heterocedasticidad y funciones de varianza." \textit{Ecología austral} (2020). doi:10.25260/ea.20.30.3.0.1131.
    \item Torrejón-Magallanes et al. "Estimación del descarte por exceso de captura en la pesquería industrial de cerco del stock Norte-Centro de la anchoveta peruana \textit{Engraulis ringens} a partir de un programa de observación a bordo." \textit{Revista peruana de biología} (2016). doi:10.15381/rpb.v23i2.12435.
    \item Atedhor. "Rainfall variability and drought during the sowing season and mid-season of rice in the Sudano-Sahelian Region of Nigeria." \textit{Journal of the Cameroon Academy of Sciences} (2019). doi:10.4314/jcas.v15i1.4.
    \item Ojo \& Baiyegunhi. "Determinants of credit constraints and its impact on the adoption of climate change adaptation strategies among rice farmers in South-West Nigeria." \textit{Journal of Economic Structures} (2020). doi:10.1186/s40008-020-00204-6.
    \item Panda et al. "Impact of Climate Variability on Crop Yield in Kalahandi, Bolangir, and Koraput Districts of Odisha, India." \textit{Climate} (2019). doi:10.3390/cli7110126.
    \item Huang et al. "Vulnerability Assessment and Adaptation Strategies for the Impact of Climate Change on Agricultural Land in Southern Taiwan." \textit{Sustainability} (2020). doi:10.3390/su12114637.
    \item Singh et al. "Implications of Farmer's Adaptation Strategies to Climate Change in Agricultural Sector of Gujarat: Experience from Farm Level Data." \textit{Research on World Agricultural Economy} (2022). doi:10.36956/rwae.v3i1.498.
    \item Siddiqui et al. "The Impact of Climate Change on Major Agricultural Crops: Evidence from Punjab, Pakistan." \textit{The Pakistan Development Review} (2022). doi:10.30541/v51i4iipp.261-276.
    \item Ahmed et al. "Climate Change Impacts and Adaptation Strategies for Agronomic Crops." (2019). doi:10.5772/intechopen.82697.
    \item Sadiku et al. "Climate-Smart Agriculture." \textit{International Journal of Advanced Research in Computer Science and Software Engineering} (2017). doi:10.23956/ijarcsse/v7i2/01202.
    \item Kumar. "Climate Change and Sugarcane Productivity in India: An Econometric Analysis." \textit{Journal of Social and Development Sciences} (2014). doi:10.22610/jsds.v5i2.811.
    \item Corrales. "Modelación predictiva de siniestros en seguros de no vida." \textit{Revista de matemática teoría y aplicaciones} (2020). doi:10.15517/rmta.v28i1.39030.
    \item Botero \& Barajas. "El impacto de especificar incorrectamente la distribución de los efectos aleatorios en las estimaciones de modelos lineales generalizados mixtos." \textit{Comunicaciones en estadística} (2017). doi:10.15332/2422474x.3267.
    \item Cruz. "Evaluación de la política de extensionismo rural en México, con base en modelos econométricos lineales y no lineales." \textit{Agricultura sociedad y desarrollo} (2024). doi:10.22231/asyd.v21i3.1621.
\end{enumerate}

